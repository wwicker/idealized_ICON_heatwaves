{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44b1758-0e7c-46de-9c7b-830ea467b874",
   "metadata": {},
   "source": [
    "# Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18806a6-b7be-4bda-84bb-98c8e9411c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cmocean\n",
    "import pandas as pd\n",
    "import matplotlib.transforms as mtransforms\n",
    "import scipy.signal\n",
    "import scipy.fft \n",
    "import numba\n",
    "\n",
    "from icon_util import regrid\n",
    "\n",
    "work = os.environ['WORK']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231fa6a3-d872-4386-b275-0461d2345015",
   "metadata": {},
   "source": [
    "## Hovmoeller composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6155ed-41ad-4b67-b7f9-51e65a04e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_composite(data,dates,central,dt=0.25):\n",
    "    \n",
    "    # cyclic data with -360 < lon < 360\n",
    "    upper = data.sel(longitude=slice(-179,0))\n",
    "    upper['longitude'] = upper['longitude'] + 360\n",
    "    lower = data.sel(longitude=slice(0,179))\n",
    "    lower['longitude'] = lower['longitude'] - 360\n",
    "    \n",
    "    cyclic = xr.concat([lower,data,upper],dim='longitude')\n",
    "    \n",
    "    rangeIndex = xr.DataArray(np.arange(len(data['time'])),coords=dict(time=data['time']))\n",
    "    \n",
    "    composite = []\n",
    "    \n",
    "    for day, lon in zip(dates.values,central.values):\n",
    "        \n",
    "        # select, subtract lon, intepolate\n",
    "        onset = cyclic.sel(time=slice(day,day+0.9)).sel(longitude=lon,method='nearest')\n",
    "        onset = onset['time'].isel(time=onset['ta'].argmax('time'))\n",
    "        i = rangeIndex.sel(time=onset).values.astype('int')\n",
    "        \n",
    "        selection = cyclic.isel(time=slice(i-40,i+40))\n",
    "        selection = selection.drop('time').rename(time='step')\n",
    "        selection = selection.assign_coords(onset=onset.values)\n",
    "        \n",
    "        selection['longitude'] = selection['longitude'] - lon\n",
    "        selection = selection.interp(longitude=range(-180,180))\n",
    "        \n",
    "        if len(selection.step)==80: composite.append(selection.assign_coords(step=np.arange(-40,40)*dt))\n",
    "        \n",
    "    return xr.concat(composite,dim='onset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a22b9-34b9-42e1-bc0c-3e3979a7e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(work+'/wolfgang/icon_postproc_t1000_mean/atm_heldsuarez_butler_exp9_t1000_mean_heatwaves.json')\n",
    "dist = xr.open_dataarray(work+'/wolfgang/icon_postproc_t1000_mean/atm_heldsuarez_butler_exp9_t1000_mean_percentiles.nc')\n",
    "\n",
    "indices = dist['ncells'].where((dist['clat']<=np.radians(53)) * (dist['clat']>=np.radians(52)),drop=True)\n",
    "samples = data[data['ncells'].isin(indices.values)]\n",
    "\n",
    "dates = samples['start'].to_xarray()\n",
    "central = np.degrees(dist['clon'].isel(ncells=samples['ncells']))\n",
    "\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f9c0a4-e84b-4fad-8170-3b8f1927f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature anomaly with respect to 90th percentile\n",
    "directory = work+'/DATA/icon_simulations/atm_heldsuarez_butler_exp9/3d/ta/100000pa/'\n",
    "\n",
    "files = [directory + f for f in os.listdir(directory) if f.endswith('.nc')]\n",
    "files.sort()\n",
    "\n",
    "ta = xr.open_mfdataset(files,combine='nested',concat_dim='time')['ta']\n",
    "\n",
    "ta = ta.sel(time=slice(1300,501300)).squeeze()\n",
    "\n",
    "ta = ta - dist.sel(p=0.9)\n",
    "\n",
    "ta = regrid(ta.drop('plev'),lim=(52,52.5),res=1)\n",
    "\n",
    "ta = ta.mean('latitude').compute()\n",
    "\n",
    "ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3aed72-3cb0-4634-b4b6-e341cfa6d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp9 = construct_composite(xr.Dataset(dict(ta=ta)),dates,central)\n",
    "\n",
    "exp9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f239d6ff-001c-4d95-aaa8-81b0dc65fc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(work+'/wolfgang/icon_postproc_t1000_mean/atm_heldsuarez_butler_exp4_t1000_mean_heatwaves.json')\n",
    "dist = xr.open_dataarray(work+'/wolfgang/icon_postproc_t1000_mean/atm_heldsuarez_butler_exp4_t1000_mean_percentiles.nc')\n",
    "\n",
    "indices = dist['ncells'].where((dist['clat']<=np.radians(44)) * (dist['clat']>=np.radians(43)),drop=True)\n",
    "samples = data[data['ncells'].isin(indices.values)]\n",
    "\n",
    "dates = samples['start'].to_xarray()\n",
    "central = np.degrees(dist['clon'].isel(ncells=samples['ncells']))\n",
    "\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d1c8c3-d27a-4bdc-a48e-e501010ea82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature anomaly with respect to 90th percentile\n",
    "directory = work+'/DATA/icon_simulations/atm_heldsuarez_butler_exp4/3d/ta/100000pa/'\n",
    "\n",
    "files = [directory + f for f in os.listdir(directory) if f.endswith('.nc')]\n",
    "files.sort()\n",
    "\n",
    "ta = xr.open_mfdataset(files,combine='nested',concat_dim='time')['ta']\n",
    "\n",
    "ta = ta.sel(time=slice(1300,501300)).squeeze()\n",
    "\n",
    "ta = ta - dist.sel(p=0.9)\n",
    "\n",
    "ta = regrid(ta.drop('plev'),lim=(43,43.5),res=1)\n",
    "\n",
    "ta = ta.mean('latitude').compute()\n",
    "\n",
    "ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3eaa2-fd0c-469e-a97a-2bfaca074911",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp4 = construct_composite(xr.Dataset(dict(ta=ta)),dates,central)\n",
    "\n",
    "exp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d90978c-a22e-4dcc-b672-f9fa6a0181cb",
   "metadata": {},
   "source": [
    "## Phase and group velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695d8d5-9f10-44ea-976d-2df410684290",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.guvectorize(   \n",
    "    \"(float64[:],int16,complex128[:])\",\n",
    "    \"(n), () -> (n)\",\n",
    "    forceobj=True\n",
    ")\n",
    "def _hilbert(y,N,out):\n",
    "    '''\n",
    "        Analytic signal using the Hilbert transform technique (Marple, 1999)\n",
    "    '''\n",
    "    # Check whether the signal has even or odd length\n",
    "    if N%2==0:\n",
    "        a = int(N/2)\n",
    "    else:\n",
    "        if N>1:\n",
    "            a = int((N-1)/2)\n",
    "        else:\n",
    "            a = 0\n",
    "        \n",
    "    # FFT of y\n",
    "    z = np.fft.fft(y)\n",
    "    \n",
    "    # Zero-out the negative frequencies\n",
    "    z[a+1:N] = 0\n",
    "    # Double the positive frequencies except from the 0th and (N/2)th ones\n",
    "    z = 2*z\n",
    "    z[0] = z[0]/2\n",
    "    if N%2==0: \n",
    "        # For the even-length case, we also have the Nyquist frequency in the spectrum. \n",
    "        # This is shared between the positive and negative frequencies so we need to keep it once (see Marple 1999). \n",
    "        # For odd lengths, there is no Nyquist frequency in the spectrum.\n",
    "        z[a] = z[a]/2\n",
    "\n",
    "    # Inverse FFT to get the analytic signal\n",
    "    out[:] = np.fft.ifft(z)\n",
    "    \n",
    "    \n",
    "@numba.vectorize([numba.float64(numba.float64, numba.float64)])\n",
    "def _rad_diff(a,b):\n",
    "    '''\n",
    "        In cases where the upstream and downstream phase differ more than pi or -pi, add/subtract 2pi where needed.\n",
    "    '''\n",
    "    diff = a - b\n",
    "    if diff > np.pi:\n",
    "        diff -= 2*np.pi\n",
    "    elif diff < -np.pi:\n",
    "        diff += 2*np.pi\n",
    "        \n",
    "    return diff\n",
    "    \n",
    "    \n",
    "@numba.guvectorize(   \n",
    "    \"(float64[:],float64[:])\",\n",
    "    \"(n) -> (n)\",\n",
    "    forceobj=True\n",
    ")    \n",
    "def _finite_difference(a,out):\n",
    "    '''\n",
    "        Use centered differences in the interior, one-sided differences at the boundaries\n",
    "    '''\n",
    "    out[1:-1] = _rad_diff(a[2:],a[:-2])/2.\n",
    "    out[-1] = _rad_diff(a[-1],a[-2])\n",
    "    out[0] = _rad_diff(a[1],a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7965d-766d-4b9f-b0cf-0728e0ad9eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.guvectorize(   \n",
    "    \"(float64[:],float64[:],float64[:])\",\n",
    "    \"(n), (n) -> (n)\",\n",
    "    forceobj=True\n",
    ")\n",
    "def _fft_filter(y,mask,out):\n",
    "    '''\n",
    "        Filter by multiplication in spectral space\n",
    "    '''\n",
    "    z = scipy.fft.fft(y)\n",
    "    z = z * mask\n",
    "    out[:] = scipy.fft.ifft(z)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def filtering(da,kmin=2,kmax=10,alpha=0.5):\n",
    "    '''\n",
    "    '''\n",
    "    # prepare mask\n",
    "    N = len(da.longitude)\n",
    "    taper = scipy.signal.tukey(kmax-kmin+1,alpha=alpha)\n",
    "    mask = np.zeros(N)\n",
    "    mask[kmin:kmax+1] = taper\n",
    "    mask = xr.DataArray(mask,dims=('freq'))\n",
    "    \n",
    "    # multiply data with mask in spectral space\n",
    "    filtered = xr.apply_ufunc(_fft_filter,\n",
    "                              *(da,mask),\n",
    "                              input_core_dims=[['longitude'],['freq']],\n",
    "                              output_core_dims=[['longitude']],\n",
    "                              dask='parallelized',\n",
    "                              output_dtypes=[da.dtype]\n",
    "                             )\n",
    "    \n",
    "    # Since the ignored negative frequencies would contribute the same as the positive ones\n",
    "    filtered *= 2 \n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673bb02b-34fa-460b-abae-619367154642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def envelope_phase(da):\n",
    "    '''\n",
    "        Absolute value and phase angle of the complex signal\n",
    "    '''\n",
    "    sig = xr.apply_ufunc(_hilbert,\n",
    "                         *(da,len(da.longitude)),\n",
    "                         input_core_dims=[['longitude'],[]],\n",
    "                         output_core_dims=[['longitude']],\n",
    "                         dask='parallelized',\n",
    "                         output_dtypes=[np.dtype('complex128')]\n",
    "                        )\n",
    "\n",
    "    env = np.abs(sig)\n",
    "    phase = np.arctan2(np.imag(sig),np.real(sig))\n",
    "    \n",
    "    return xr.Dataset(dict(env=env,phase=phase))\n",
    "\n",
    "\n",
    "def wavenum_speed(phase,lat=51,dt=6*3600):\n",
    "    '''\n",
    "        Use finite differences to estimate wavenumber and phase speed\n",
    "    '''\n",
    "    # radians per time step\n",
    "    freq = xr.apply_ufunc(_finite_difference,\n",
    "                          phase,\n",
    "                          input_core_dims=[['step']],\n",
    "                          output_core_dims=[['step']],\n",
    "                          dask='parallelized',\n",
    "                          output_dtypes=[np.double]\n",
    "                         )\n",
    "    \n",
    "    # radians per grid spacing\n",
    "    wavenum = xr.apply_ufunc(_finite_difference,\n",
    "                             phase,\n",
    "                             input_core_dims=[['longitude']],\n",
    "                             output_core_dims=[['longitude']],\n",
    "                             dask='parallelized',\n",
    "                             output_dtypes=[np.double]\n",
    "                            )\n",
    "    \n",
    "    # grid spacing per time step\n",
    "    speed = freq / wavenum\n",
    "    # grid spacing per second\n",
    "    speed = speed / (-dt)\n",
    "    # meter per second\n",
    "    speed = speed * (2*np.pi*6371000) * np.cos(np.radians(lat)) / (len(speed['longitude'])-1)\n",
    "    \n",
    "    # cycles per circumference\n",
    "    wavenum = wavenum / (2*np.pi) * len(wavenum['longitude'])\n",
    "    \n",
    "    return xr.Dataset(dict(wavenum=wavenum,speed=speed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30edf90a-4522-4d22-9e8a-35982a0f10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = filtering(exp9['ta'].mean('onset'),kmin=3,kmax=15,alpha=0.5)\n",
    "ds = envelope_phase(da)\n",
    "group = envelope_phase(ds['env'])\n",
    "\n",
    "exp9_wave = xr.Dataset(dict(wave=ds['phase'],envelope=ds['env'],group=group['phase']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f45c7e-b484-4fd5-8655-bacd1ee2d38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = filtering(exp4['ta'].mean('onset'),kmin=3,kmax=15,alpha=0.5)\n",
    "ds = envelope_phase(da)\n",
    "group = envelope_phase(ds['env'])\n",
    "\n",
    "exp4_wave = xr.Dataset(dict(wave=ds['phase'],envelope=ds['env'],group=group['phase']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052e4cfb-dfbd-4fba-9b15-e15db24dbe9c",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c89ea-fafb-40c4-9efc-dbe651f72ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3,figsize=(8,10))\n",
    "\n",
    "\n",
    "C = exp9['ta'].mean('onset').plot(ax=axes[0],levels=np.linspace(-8,8,17),extend='both',add_colorbar=False)\n",
    "\n",
    "exp9_wave['wave'].where(exp9_wave['envelope']>0.5).plot.contour(ax=axes[0],levels=[0,],colors='k',linestyles=':',alpha=0.6)\n",
    "exp9_wave['group'].where(exp9_wave['envelope']>0.5).plot.contour(ax=axes[0],levels=[0,],colors='k',alpha=0.6)\n",
    "\n",
    "C0 = exp9_wave['envelope'].plot.contour(ax=axes[0],levels=np.arange(0.5,5,0.5),colors='w',alpha=0.8)\n",
    "\n",
    "plt.clabel(C0,levels=np.arange(1,4.5),fontsize='x-small',colors='k')\n",
    "\n",
    "\n",
    "\n",
    "exp4['ta'].mean('onset').plot(ax=axes[1],levels=np.linspace(-8,8,17),extend='both',add_colorbar=False)\n",
    "\n",
    "exp4_wave['wave'].where(exp4_wave['envelope']>0.5).plot.contour(ax=axes[1],levels=[0,],colors='k',linestyles=':',alpha=0.6)\n",
    "exp4_wave['group'].where(exp4_wave['envelope']>0.5).plot.contour(ax=axes[1],levels=[0,],colors='k',alpha=0.6)\n",
    "\n",
    "C0 = exp4_wave['envelope'].plot.contour(ax=axes[1],levels=np.arange(0.5,5,0.5),colors='w',alpha=0.8)\n",
    "\n",
    "plt.clabel(C0,levels=np.arange(1,4.5),fontsize='x-small',colors='k')\n",
    "\n",
    "\n",
    "exp9_wave['wave'].where(exp9_wave['envelope']>0.5).plot.contour(ax=axes[2],levels=[0,],colors='#1f77b4',linestyles=':')\n",
    "exp9_wave['group'].where(exp9_wave['envelope']>0.5).plot.contour(ax=axes[2],levels=[0,],colors='#1f77b4',linewidths=1)\n",
    "exp9['ta'].mean('onset').plot.contour(ax=axes[2],levels=[0,],colors='#1f77b4')\n",
    "\n",
    "exp4_wave['wave'].where(exp4_wave['envelope']>0.5).plot.contour(ax=axes[2],levels=[0,],colors='#ff7f0e',linestyles=':')\n",
    "exp4_wave['group'].where(exp4_wave['envelope']>0.5).plot.contour(ax=axes[2],levels=[0,],colors='#ff7f0e',linewidths=1)\n",
    "exp4['ta'].mean('onset').plot.contour(ax=axes[2],levels=[0,],colors='#ff7f0e')\n",
    "\n",
    "\n",
    "l1 = axes[2].plot([],[],color='#1f77b4')\n",
    "l2 = axes[2].plot([],[],color='#ff7f0e')\n",
    "\n",
    "axes[2].legend([*l1,*l2],['Tropical warming','Arctic warming'],loc='upper left',fontsize=10)\n",
    "\n",
    "\n",
    "for ax in axes:\n",
    "    \n",
    "    ax.plot(ax.get_xlim(),[0,0],linestyle=':',linewidth=0.5,color='k')\n",
    "    ax.plot([0,0],ax.get_ylim(),linestyle=':',linewidth=0.5,color='k')\n",
    "\n",
    "    ax.set_title('')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_ylim(-8,8)\n",
    "    ax.set_xticks([-180,-120,-60,0,60,120,180])\n",
    "    ax.set_yticks([-8,-4,0,4,8],minor=False)\n",
    "    \n",
    "    \n",
    "axes[0].set_title('Tropical warming',weight='bold',fontsize='smaller')\n",
    "axes[1].set_title('Arctic warming',weight='bold',fontsize='smaller')\n",
    "\n",
    "axes[2].set_xlabel('Relative longitude [°E] relative to grid point')\n",
    "axes[1].set_ylabel('Lag [days] relative to heatwave onset',fontsize=16)\n",
    "\n",
    "axes[0].set_xticklabels([])\n",
    "axes[1].set_xticklabels([])\n",
    "\n",
    "\n",
    "cbar = plt.colorbar(C,ax=axes[:2],aspect=30)\n",
    "cbar.set_label('T1000 anomaly [K] from 90th percentile')\n",
    "\n",
    "box = list(axes[2].get_position().bounds)\n",
    "box[2] = axes[1].get_position().bounds[2]\n",
    "axes[2].set_position(box)\n",
    "\n",
    "trans = mtransforms.ScaledTranslation(-45/72, -20/72, fig.dpi_scale_trans)\n",
    "\n",
    "axes[0].text(-0.1,1.06,'a)',transform=axes[0].transAxes+trans,fontsize='large',va='bottom')\n",
    "axes[1].text(-0.1,1.06,'b)',transform=axes[1].transAxes+trans,fontsize='large',va='bottom')\n",
    "axes[2].text(-0.1,1.06,'c)',transform=axes[2].transAxes+trans,fontsize='large',va='bottom')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5bffb-b682-4c60-af8e-310cc3602b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a146be1-471e-408a-877c-5800eaac05cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2c5dc-1c5a-4d24-89ad-c3de8ca63814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fdb935-02a5-4417-ad28-fcc560ec1f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python-2023]",
   "language": "python",
   "name": "conda-env-python-2023-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
